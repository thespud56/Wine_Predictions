{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing.dummy import Pool\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "\n",
    "\n",
    "BASE_URL = 'http://www.winemag.com/?s=&drink_type=wine&page={0}'\n",
    "session = requests.Session()\n",
    "HEADERS = {\n",
    "    'user-agent': ('Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 '\n",
    "                   '(KHTML, like Gecko) Chrome/48.0.2564.109 Safari/537.36')\n",
    "}\n",
    "DATA_DIR = 'data'\n",
    "FILENAME = 'winemag-data'\n",
    "\n",
    "UNKNOWN_FORMAT = 0\n",
    "APPELLATION_FORMAT_0 = 1\n",
    "APPELLATION_FORMAT_1 = 2\n",
    "APPELLATION_FORMAT_2 = 3\n",
    "\n",
    "\n",
    "#class Scraper():\n",
    "    \"\"\"Scraper for Winemag.com to collect wine reviews\"\"\"\n",
    "\n",
    "    def __init__(self, pages_to_scrape=(1,1), num_jobs=1, clear_old_data=True):\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.num_jobs = num_jobs\n",
    "        self.clear_old_data = clear_old_data\n",
    "        self.session = requests.Session()\n",
    "        self.start_time = time.time()\n",
    "        self.cross_process_review_count = 0\n",
    "        self.estimated_total_reviews = (pages_to_scrape[1] + 1 - pages_to_scrape[0]) * 30\n",
    "\n",
    "        if num_jobs > 1:\n",
    "            self.multiprocessing = True\n",
    "            self.worker_pool = Pool(num_jobs)\n",
    "        else:\n",
    "            self.multiprocessing = False\n",
    "\n",
    "    def scrape_site(self):\n",
    "        if self.clear_old_data:\n",
    "            self.clear_data_dir()\n",
    "        if self.multiprocessing:\n",
    "            link_list = [BASE_URL.format(page) for page in range(self.pages_to_scrape[0],self.pages_to_scrape[1] + 1)]\n",
    "            records = self.worker_pool.map(self.scrape_page, link_list)\n",
    "            self.worker_pool.terminate()\n",
    "            self.worker_pool.join()\n",
    "        else:\n",
    "            for page in range(self.pages_to_scrape[0], self.pages_to_scrape[1] + 1):\n",
    "                self.scrape_page(BASE_URL.format(page))\n",
    "        print('Scrape finished...')\n",
    "        self.condense_data()\n",
    "\n",
    "    def scrape_page(self, page_url, isolated_review_count=0, retry_count=0):\n",
    "        scrape_data = []\n",
    "        try:\n",
    "            response = self.session.get(page_url, headers=HEADERS)\n",
    "        except:\n",
    "            retry_count += 1\n",
    "            if retry_count <= 3:\n",
    "                self.session = requests.Session()\n",
    "                self.scrape_page(page_url, isolated_review_count, retry_count)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Drop the first review-item; it's always empty\n",
    "        reviews = soup.find_all('li', {'class': 'review-item'})[1:]\n",
    "        for review in reviews:\n",
    "            self.cross_process_review_count += 1\n",
    "            isolated_review_count += 1\n",
    "            review_url = review.find('a', {'class': 'review-listing'})['href']\n",
    "            try:\n",
    "                review_data = self.scrape_review(review_url)\n",
    "            except Exception as e:\n",
    "                print('Encountered error', e)\n",
    "                continue\n",
    "            scrape_data.append(review_data)\n",
    "            self.update_scrape_status()\n",
    "        self.save_data(scrape_data)\n",
    "\n",
    "\n",
    "    def scrape_review(self, review_url):\n",
    "        review_response = self.session.get(review_url, headers=HEADERS)\n",
    "        review_soup = BeautifulSoup(review_response.content, 'html.parser')\n",
    "        try:\n",
    "            return self.parse_review(review_soup)\n",
    "        except ReviewFormatException as e:\n",
    "            print('\\n-----\\nError parsing: {}\\n{}\\n-----'.format(\n",
    "                review_url,\n",
    "                e.message\n",
    "            ))\n",
    "\n",
    "    def parse_review(self, review_soup):\n",
    "        review_format = self.determine_review_format(review_soup)\n",
    "        points = review_soup.find(\"span\", {\"id\": \"points\"}).contents[0]\n",
    "        title = review_soup.find(\"div\", {\"class\", \"article-title\"}).contents[0]\n",
    "        description = review_soup.find(\"p\", {\"class\": \"description\"}).contents[0]\n",
    "\n",
    "        try:\n",
    "            taster_name = review_soup.find(\"div\", {\"class\", \"taster\"}).find(\"div\", {\"class\", \"name\"})\n",
    "            if taster_name is not None:\n",
    "                taster_name = taster_name.contents[0]\n",
    "\n",
    "            taster_twitter_handle = review_soup.find(\"div\", {\"class\", \"taster\"}).find(\"div\", {\"class\", \"twitter-handle\"})\n",
    "            if taster_twitter_handle is not None:\n",
    "                taster_twitter_handle = taster_twitter_handle.contents[0]\n",
    "        except:\n",
    "            taster_name = None\n",
    "            taster_twitter_handle = None\n",
    "\n",
    "        info_containers = review_soup.find(\n",
    "            'ul', {'class': 'primary-info'}).find_all('li', {'class': 'row'})\n",
    "\n",
    "        if review_format['price_index'] is not None:\n",
    "            try:\n",
    "                price_string = info_containers[review_format['price_index']].find(\n",
    "                    'div', {'class': 'info'}).span.span.contents[0].split(',')[0]\n",
    "            except:\n",
    "                raise ReviewFormatException('Unexpected price format')\n",
    "            # Sometimes price is N/A\n",
    "            try:\n",
    "                price = int(re.sub('[$]', '', price_string))\n",
    "            except ValueError:\n",
    "                price = None\n",
    "        else:\n",
    "            price = None\n",
    "\n",
    "        if review_format['designation_index'] is not None:\n",
    "            try:\n",
    "                designation = info_containers[review_format['designation_index']].find('div', {'class': 'info'}).span.span.contents[0]\n",
    "            except:\n",
    "                raise ReviewFormatException('Unexpected designation format')\n",
    "        else:\n",
    "            designation = None\n",
    "\n",
    "        if review_format['variety_index'] is not None:\n",
    "            try:\n",
    "                variety = info_containers[review_format['variety_index']].find(\n",
    "                    'div', {'class': 'info'}).span.findChildren()[0].contents[0]\n",
    "            except:\n",
    "                raise ReviewFormatException('Unexpected variety format')\n",
    "        else:\n",
    "            variety = None\n",
    "\n",
    "        if review_format['appellation_index'] is not None:\n",
    "            appellation_info = info_containers[review_format['appellation_index']].find('div', {'class': 'info'}).span.findChildren()\n",
    "            try:\n",
    "                if review_format['appellation_format'] == APPELLATION_FORMAT_0:\n",
    "                    region_1 = None\n",
    "                    region_2 = None\n",
    "                    province = appellation_info[0].contents[0]\n",
    "                    country = appellation_info[1].contents[0]\n",
    "                elif review_format['appellation_format'] == APPELLATION_FORMAT_1:\n",
    "                    region_1 = appellation_info[0].contents[0]\n",
    "                    region_2 = None\n",
    "                    province = appellation_info[1].contents[0]\n",
    "                    country = appellation_info[2].contents[0]\n",
    "                elif review_format['appellation_format'] == APPELLATION_FORMAT_2:\n",
    "                    region_1 = appellation_info[0].contents[0]\n",
    "                    region_2 = appellation_info[1].contents[0]\n",
    "                    province = appellation_info[2].contents[0]\n",
    "                    country = appellation_info[3].contents[0]\n",
    "                else:\n",
    "                    region_1 = None\n",
    "                    region_2 = None\n",
    "                    province = None\n",
    "                    country = None\n",
    "            except:\n",
    "                raise ReviewFormatException('Unknown appellation format')\n",
    "        else:\n",
    "            region_1 = None\n",
    "            region_2 = None\n",
    "            province = None\n",
    "            country = None\n",
    "\n",
    "        if review_format['winery_index'] is not None:\n",
    "            try:\n",
    "                winery = info_containers[review_format['winery_index']].find(\n",
    "                    'div', {'class': 'info'}).span.span.findChildren()[0].contents[0]\n",
    "            except:\n",
    "                raise ReviewFormatException('Unexpected winery format')\n",
    "        else:\n",
    "            winery = None\n",
    "\n",
    "        review_data = {\n",
    "            'points': points,\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "            'taster_name': taster_name,\n",
    "            'taster_twitter_handle': taster_twitter_handle,\n",
    "            'price': price,\n",
    "            'designation': designation,\n",
    "            'variety': variety,\n",
    "            'region_1': region_1,\n",
    "            'region_2': region_2,\n",
    "            'province': province,\n",
    "            'country': country,\n",
    "            'winery': winery\n",
    "        }\n",
    "        return review_data\n",
    "\n",
    "    def determine_review_format(self, review_soup):\n",
    "        review_format = {}\n",
    "        info_containers = review_soup.find(\n",
    "            'ul', {'class': 'primary-info'}).find_all('li', {'class': 'row'})\n",
    "\n",
    "        review_info = []\n",
    "        for container in info_containers:\n",
    "            review_info.append(str(container.find('span').contents[0]).lower())\n",
    "\n",
    "        try:\n",
    "            review_format['price_index'] = review_info.index('price')\n",
    "        except ValueError:\n",
    "            review_format['price_index'] = None\n",
    "        try:\n",
    "            review_format['designation_index'] = review_info.index('designation')\n",
    "        except ValueError:\n",
    "            review_format['designation_index'] = None\n",
    "        try:\n",
    "            review_format['variety_index'] = review_info.index('variety')\n",
    "        except ValueError:\n",
    "            review_format['variety_index'] = None\n",
    "        try:\n",
    "            review_format['appellation_index'] = review_info.index('appellation')\n",
    "        except ValueError:\n",
    "            review_format['appellation_index'] = None\n",
    "        try:\n",
    "            review_format['winery_index'] = review_info.index('winery')\n",
    "        except ValueError:\n",
    "            review_format['winery_index'] = None\n",
    "\n",
    "        # The appellation format changes based on where in the world the winery is located\n",
    "        if review_format['appellation_index'] is not None:\n",
    "            appellation_info = info_containers[review_format['appellation_index']].find('div', {'class': 'info'}).span.findChildren()\n",
    "            if len(appellation_info) == 2:\n",
    "                review_format['appellation_format'] = APPELLATION_FORMAT_0\n",
    "            elif len(appellation_info) == 3:\n",
    "                review_format['appellation_format'] = APPELLATION_FORMAT_1\n",
    "            elif len(appellation_info) == 4:\n",
    "                review_format['appellation_format'] = APPELLATION_FORMAT_2\n",
    "            else:\n",
    "                review_format['appellation_format'] = UNKNOWN_FORMAT\n",
    "\n",
    "        return review_format\n",
    "\n",
    "    def save_data(self, data):\n",
    "        filename = '{}/{}_{}.json'.format(DATA_DIR, FILENAME, time.time())\n",
    "        try:\n",
    "            os.makedirs(DATA_DIR)\n",
    "        except OSError:\n",
    "            pass\n",
    "        with open(filename, 'w') as fout:\n",
    "            json.dump(data, fout)\n",
    "\n",
    "    def clear_all_data(self):\n",
    "        self.clear_data_dir()\n",
    "        self.clear_output_data()\n",
    "\n",
    "    def clear_data_dir(self):\n",
    "        try:\n",
    "            shutil.rmtree(DATA_DIR)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    def clear_output_data(self):\n",
    "        try:\n",
    "            os.remove('{}.json'.format(FILENAME))\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    def condense_data(self):\n",
    "        print('Condensing Data...')\n",
    "        condensed_data = []\n",
    "        all_files = glob.glob('{}/*.json'.format(DATA_DIR))\n",
    "        for file in all_files:\n",
    "            with open(file, 'rb') as fin:\n",
    "                condensed_data += json.load(fin)\n",
    "        print(len(condensed_data))\n",
    "        filename = '{}.json'.format(FILENAME)\n",
    "        with open(filename, 'w') as fout:\n",
    "            json.dump(condensed_data, fout)\n",
    "\n",
    "    def update_scrape_status(self):\n",
    "        elapsed_time = round(time.time() - self.start_time, 2)\n",
    "        time_remaining = round((self.estimated_total_reviews - self.cross_process_review_count) * (self.cross_process_review_count / elapsed_time), 2)\n",
    "        print('{0}/{1} reviews | {2} sec elapsed | {3} sec remaining\\r'.format(\n",
    "            self.cross_process_review_count, self.estimated_total_reviews, elapsed_time, time_remaining))\n",
    "\n",
    "\n",
    "class ReviewFormatException(Exception):\n",
    "    \"\"\"Exception when the format of a review page is not understood by the scraper\"\"\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "        super(Exception, self).__init__(message)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Total review results on their site are conflicting, hardcode as the max tested value for now\n",
    "    pages_to_scrape = (1, 7554)\n",
    "    winmag_scraper = Scraper(pages_to_scrape=pages_to_scrape, num_jobs=10, clear_old_data=False)\n",
    "\n",
    "    # Step 1: scrape data\n",
    "    winmag_scraper.scrape_site()\n",
    "\n",
    "    # Step 2: condense data\n",
    "    winmag_scraper.condense_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
